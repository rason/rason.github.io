title: 网站的伸缩性
categories: Architecture
date: 2016-03-30 08:48:19
tags: Architecture
description: 网站的伸缩性
---

## 前言

所谓网站的伸缩性是指不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或者缩小网站的服务处理能力。通过之前的学习，我们第一时间能想到的方法就是使用集群。所以，怎么才能做到只要向集群中添加服务器就能增强系统的处理能力是我们需要解决的问题。

## 网站的伸缩性架构

集群的使用当然是伸缩性架构的重要手段。然而，在网站的一开始阶段，我们可能并不需要集群,只需按功能分离即可，如果还记得网站架构演变过程的话。

因此，网站的伸缩性设计可以分为两类：

- **根据功能进行物理分离实现伸缩**：不同服务器部署不同的服务
- **单一功能通过集群实现伸缩**：多台服务器部署相同的服务

在网站的早期，通常会使用第一种方式，如图：

![根据功能进行物理分离实现伸缩](/image/architecture-scalable-1.png)

<!-- more -->

当然，根据功能分离也可以用于网站发展的任何阶段。具体还可以分为两种情况：

- **纵向分离（分层后分离）**：将业务处理流程上的不同部分分离部署。

![纵向分离部署实现伸缩](/image/architecture-scalable-2.png)

- **横向分离（业务分割后分离）**：将不同的业务模块分离部署。

![横向分离部署实现伸缩](/image/architecture-scalable-3.png)

当然，将不同功能分离之后可以实现一定程度的伸缩性，但是随着网站的访问量增加，及时分离到最小力度的独立部署，单一的服务器也会成为瓶颈。此时，就需要使用集群了，即多台服务器部署相同的服务。

**当一头牛拉不动车的时候，不要去寻找一头更强壮的牛，而是用两头牛来拉车**

具体来说，集群伸缩性分为两种：

- **应用服务器集群伸缩性**
- **数据服务器集群伸缩性**
  - **缓存数据服务器集群**
  - **存储数据服务器集群**

这几种集群的技术实现有着较大的区别，所以得分开讨论。

## 应用服务器集群的伸缩性设计

应用服务器集群伸缩性设计，重点就是负载均衡技术，将请求分发到不同的服务器来处理。

实现负载均衡的基础技术包含以下几种：

**1.HTTP重定向负载均衡**
**2.DNS域名解析负载均衡**
**3.反向代理负载均衡**
**4.IP负载均衡**
**5.数据链路层负载均衡**

### HTTP重定向负载均衡

HTTP重定向服务器是一台普通的应用服务器，其唯一功能就是根据用户的HTTP请求计算一台真实的Web服务器地址，并强该Web服务器地址写入HTTP重定向响应中（响应状态吗302）返回给用户浏览器。如图所示：

![HTTP重定向负载均衡原理](/image/architecture-loadbalance-1.png)

HTTP重定向服务器是根据一定的负载均衡算法找到真实的服务器。实际上这种方案很少使用，两次请求才能完成一次访问，性能太差。

### DNS域名解析负载均衡

就是**在DNS服务器中配置多条A记录**，将一个域名映射到多个IP地址，每个IP地址就是一个应用服务器,这种方式将负载均衡的工作交给了DNS。优点是，DNS会将域名解析成距离用户最近的服务器地址，加快访问；缺点是：某台服务器下线，DNS没那么快生效，会导致访问失败，而且负载均衡的控制器在域名服务商哪里，自己无法做更多改善。如图所示：

![DNS域名解析负载均衡原理](/image/architecture-loadbalance-2.png)

这种方式通常会用于作为**一级负载均衡手段**，即DNS解析出来的IP地址对应的服务器是一组负载均衡服务器，不是实际提供应用服务的服务器。

### 反向代理负载均衡

反向代理不仅可以缓存一下静态资源，还可以实现负载均衡，其工作原理如下图所示：

![反向代理负载均衡原理](/image/architecture-loadbalance-3.png)

在这种方式中，Web服务器不直接对外提供访问，因此Web服务器不需要使用外部IP地址，而**反响代理服务器则需要配置双网卡和内部外部两套IP地址**。

由于反向代理服务器转发请求在HTTP协议层面，因此也叫应用层负载均衡。**优点是部署简单，缺点是所有请求和响应的中转站，其性能可能会成为瓶颈**。

### IP负载均衡

所谓IP负载均衡，即**在网络层通过修改目标地址进行负载均衡。**如图所示：

![IP负载均衡原理](/image/architecture-loadbalance-4.png)

在这里需要处理关键的地方就是如何将集群内部服务器处理完后的数据返回给负载均衡服务器。解决办法：

- 负载均衡服务器使用双网卡，一个对内一个对外，在修改请求数据包的目的IP的同时也修改源地址，将源地址设为自身的IP，即源地址转换，这样内部集群服务器响应会再回到负载均衡服务器；

- 将负载均衡服务器作为真实物理服务器集群的网关服务器，这样所有的响应都将通过负载均衡服务器。

IP负载均衡在内核进程完成数据分发，较反向代理负载均衡有更好的处理性能。但请求响应还是得经过负载均衡服务器，所以集群的最大响应数据吞吐量还是会受限于负载均衡服务器的网卡带宽。视频下载类网站就难以满足了。**那么有没有方式让负载均衡服务器只转发请求，响应数据直接返回给用户？**

### 数据链路层负载均衡

**数据链路层负载均衡是至在通信协议的数据链路层修改mac地址进行负载均衡**，如图所示：

![数据链路层负载均衡原理](/image/architecture-loadbalance-5.png)

这种数据传输方式又称作**三角传输模式**，可以避免负载均衡服务器网卡带宽成为瓶颈。这种负载均衡方式又称作**直接路由方式（DR）**。使用三角传输模式的链路层负载均衡是目前大型网站**使用最广的一种负载均衡手段**，在Linux平台上最好的链路层负载均衡开源产品是**LVS**。

### 负载均衡算法

前面描述了如何将请求数据发送到Web服务器，而具体的负载均衡算法通常有一下几种：

- **轮询**:依次分发。
- **加权轮询**：在轮询基础上，按照权重分发。
- **随机**：随机数本身比较均衡，也可以加权随机。
- **最少连接**：分发到最少连接的服务器，同样也可以加权最少连接。
- **源地址散列**：根据请求IP进行Hash计算，同IP总会到同一服务器，可以实现会话粘滞。

## 分布式缓存集群的伸缩性设计

和应用服务器集群不同，分布式缓存服务器集群中不同服务器缓存的数据是不一样的。这个特点会严重制约分布式缓存集群的伸缩性设计，因为新上线的缓存服务器没有缓存任何数据，而已下线的缓存服务器还缓存着网站的许多热点数据。

所以，让新上线的缓存服务器对整个分布式缓存集群影响最小，也就是说**新加入缓存服务器后应使整个缓存服务器集群中已经缓存的数据尽可能还被访问到**,这是分布式缓存集群伸缩性设计的主要目标。

### Memcached分布式缓存集群的访问模型

以Memcached为代表的分布式缓存，访问模型如图：

![Memcached分布式缓存访问模型](/image/architecture-cache-lb-1.png)

该模型的简单路由算法可以**使用KEY的Hash值求余得到一台服务器，然后进行读写操作**。如果不考虑缓存服务器集群伸缩性，余数Hash几乎可以满足绝大多数的缓存路由需求。

然后，当我们需要将缓存服务器扩容的时候，问题就来了。比如机器由3台变成4台，这样求余的话大约有75%的缓存不能命中了，这显然不能接受。所以我们需要改进路由算法，常用的就是**分布式缓存的一致性Hash算法**。

**分布式缓存的一致性Hash算法**：通过一个叫做一致性Hash环的数据结构实现KEY到缓存服务器的Hash映射。如图所示：

![一致性Hash算法原理](/image/architecture-cache-hash-1.png)

具体算法过程：先构造一个长度为0~2的32次方的整数环（这个环被称作一致性Hash环），根据节点名称的Hash值将缓存服务器节点放置在这个Hash环上。然后根据需要缓存的数据的KEY值计算得到其Hash值，然后在Hash环上顺时针查找距离这个KEY的Hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找。

这个算法，3台服务器扩容至4台，可以继续命中原有缓存数据的概率是75%，远高于余数Hash的25%，而且随着集群规模越大，继续命中原有缓存数据的概率也逐渐增大。

**但是，上面描述的算法过程还存在点小问题，那就是负载均衡性还不够好。**

解决负载均衡问题可以通过**虚拟层**的手段：将每台物理缓存服务器虚拟为一组虚拟缓服务器，将虚拟服务器的Hash值放置在Hash环上，KEY在环上先找到虚拟服务器节点，再得到物理服务器的信息。具体此处不展开，自行搜索一致性Hash即可。

## 数据存储服务器集群的伸缩性设计

相对与缓存服务器集群，数据存储服务器集群对数据的持久性和可用性提出了更高的要求。因为缓存部分丢失不会影响业务，数据存储服务器则必须保证数据的可靠存储。

具体来说，数据存储集群伸缩性又分为两种：

- **关系数据库集群伸缩性**
- **NoSQL数据库集群伸缩性**

### 关系数据库集群伸缩性设计

使用数据复制功能可以对数据库进行简单伸缩，如图所示：

![MySQL集群伸缩性方案](/image/architecture-db-cluster-1.png)

这种架构中，主从复制，读写分离，另外前面提到的按业务分割模式也可以用在数据库，不同业务数据库表部署在不同的数据库集群上，俗称**分库**。分库方式的制约条件是跨库的表不能进行Join操作。

可是，如果**单表数据过大，还需要进行分片**，将一张表拆开分别存储在多个数据库中。

支持分片的分布式关系数据库产品主要有**Amoeba**和**Cobar**。

以Cobar为例，部署模型如图：

![Cobar部署模型](/image/architecture-cobar-1.png)

Cobar是一个分布式关系**数据库访问代理**，介于应用服务器和数据库服务器之间。应用程序通过JDBC驱动访问Cobar集群，Cobar服务器根据SQL和分库规则分解SQL，分发到MySql集群不同的数据库实例上执行。

![Cobar系统组件模型](/image/architecture-cobar-2.png)

**那么Cobar如何做集群的伸缩？**

两种方式：

- Cobar服务器集群的伸缩
- MySQL服务器集群的伸缩

Cobar服务器可以看作是无状态的应用服务器，因此其集群伸缩性可以简单使用负载均衡的手段实现。而MySQL中存储着数据，想要保证集群扩容后数据一致负载均衡，必须要做数据迁移，将集群中原来机器中的数据迁移到新添加的机器中。如图所示：

![Cobar集群伸缩性原理](/image/architecture-cobar-3.png)

关于数据如何迁移问题，此处也不展开，自行搜索了解。

## NoSQL数据库的伸缩性设计

NoSQL，主要指非关系的、分布式的数据库设计模式。一般而已，NoSQL数据库产品放弃了关系数据库的两大重要基础：以关系代数为基础的结构化查询语言（SQL）和事务一致性保证（ACID）。而强化大型网站更关注的特点：高可用性和伸缩性。

开源社区有各种的NoSQL产品，其支持的数据结构和伸缩特性也各不相同，目前看来，应用比较广泛的是Apache HBase。

关于NoSQL的伸缩性设计就不展开了。

## 总结

一个具有良好伸缩性架构设计的网站，其设计总是走在业务发展的前面，在业务需要处理更多访问和服务之前，就已经做好充足的准备，当业务需要时，只需购买或者租用服务器简单部署实施就可以了。
