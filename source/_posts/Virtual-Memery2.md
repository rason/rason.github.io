title: 虚拟内存（二）
categories: OS
date: 2016-10-13 10:25:10
tags: 虚拟内存
description: 虚拟内存
---

## 前言

为了解决软件膨胀和一次性加载程序到内存耗时过长的问题，我们使用了分页的技术。这么回想一下，计算机中的很多思想其实都是想通的，很多情况下都会用到类似的切分思想，比如数据库分库、大型网站横向切分和纵向切分。甚至典故曹聪称象，是不是相当于将一个大象等价切分成一块块的石头？技术中的思想和生活中的思想很多情况下也是一致的。

扯得有点远了，今天需要讨论一下分页技术带来的问题：

- **分页引入了虚拟地址到物理地址的映射，这一动作必然是耗时的，如何加快这一动作？**

- **如果虚拟地址空间很大，那么页表也会很大，如何进行管理？**

第一个问题是由于每次访问内存，都需要进行虚拟地址到物理地址的映射。所有的指令最终都必须来自内存，并且很多指令也会访问内存中的操作数。因此，每条指令会进行一两次甚至更多页表访问。

第二个问题是由于现代计算机使用至少32位的虚拟地址，而且64位也越来越普遍。假设页长为4KB，32位的地址空间将有100万页，而64位地址空间则会多到你无法想象。试想一下100万条页表项需要多少存储空间？上下文切换需要多少时间？请记住，每个进程都需要有自己的页表（因为它有自己的虚拟地址空间）。

## 加速分页过程

我们先来讨论一下第一个问题，如何加速分页映射的问题。核心思想就是利用**缓存**，二八定律在很多方面都是适用的，**大多数程序总是对少量的页面进行多次的访问**。

### 转换检测缓冲区

在不使用分页的时候，执行一条简单的指令可能只访问一次内存，即从内存中取出指令。有了分页，则因为要访问页表而引起更多次的内存访问。这样的话性能就下降了一半，因此需要使用**缓存**的思想减少内存的访问。计算机中是用一个小型的硬件设备来实现这一功能，将虚拟地址直接映射到物理地址，而不必再访问页表。这种设备称为**转换检测缓冲区（Translation Lookaside Buffer, TLB）**。如下图所示：

![TLB加速分页](/image/TLB-SPEED-UP)

<!-- more -->

TLB通常在MMU中，包含少量的表项，在上图中为8个，在实际中很少会超过64个。每个表项记录了一个页面的相关信息，包括有效位、虚拟页号、页面的修改位、保护位和该页的物理页框。除了虚拟页号（不是必须放在页表中的），这些域与页表中的域是一一对应的。

有了TLB之后，将一个虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时（即并行）进行匹配，判断虚拟页面是否在其中。如果发现了，并且没有违反保护位，则将页框号取出来而不再访问页表。如果在但是违反了保护位，则会产生一个保护错误。

如果MMU检测到没有有效的匹配时，就会进行正常的页表查询。接着从TLB中淘汰一个表项，然后用新找到的页表项代替它。这样，如果这一页面很快再被访问，第二次访问TLB时自然将会命中。当然，这里的替换可能会涉及到替换算法，暂时还没学习到，先留个坑。

## 针对大内存的页表

第二个问题就是如何来处理巨大的虚拟地址空间问题了，下面讨论两种解决方法。

### 多级页表

前言中说到，巨大的虚拟空间地址页表就非常巨大，所以占用的空间也多。一个比较小的程序，根本不需要用到那么多空间，所以页表中大部分的页表项其实是没用到的。使用多级分页，就可以大大减少页表所占用的空间，并且能避免把全部页表一直保存在内存中。

举个例子，如下图所示，32位的虚拟地址被划分为10位的PT1域、10位的PT2域和12位的Offset域。因为偏移量是12位，所以页面长度是4KB，共有2的20次方个页面。

![二级页表](/image/L2-TABLE)

在上图中，左边的是顶级页表，它具有1024个表项，对应于10位的PT1域。当一个虚拟地址被送到MMU时：

- **MMU首先提取PT1域并把该值作为访问顶级页表的索引。**

- **由索引顶级页表得到的表项中含有二级页表的地址或页框号，然后把PT2作为访问选定的二级页表的索引，以便找到该虚拟页面对应的页框号。**

- **如果该页面不在内存中，引发缺页中断；如果在内存中，从二级页表中得到的页框号将与偏移量结合形成物理地址。该地址被放到总线上并送到内存中。**

比如一个需要12MB内存的进程，顶级页表的表项0指向程序正文的页表，表项1指向数据的页表，表项1023指向堆栈的页表，其他的表项未用。这样的话，虚拟地址空间超过100万个页面，使用二级分页，这个进程实际上只需要四个页表：顶级页表和三个二级页表。其它二级页表该进程根本不需要用到就不用保存在内存中了，大大节约空间。甚至二级页表也可以使用按需加载？这个问题有待考证。

需要注意的是访问顶级页表发生缺页中断的话表示进程试图访问一个不希望被访问的地址，因为该进程根本没用到该部分地址，操作系统会采取适当的行动，比如向进程发出一个信号或杀死进程；访问二级页表发生缺页中断的话就跟不分级的处理方式一样。

另外，二级页表可扩充为三级、四级或更多级。级别越多，灵活性就越大，但页表超过三级会带来更大的复杂性，这样做是否值得令人怀疑。

### 倒排页表

对于32位虚拟地址空间，多级页表可以很好地发挥作用。但是，随着64位计算机变得更加普遍，情况就发生了彻底的变化，因为那根本就不是同一个量级。如果地址空间是2的64次方字节，页面大小为4KB，我们需要一个有2的52次方个表项的页表。如果每一个表项8个字节，那么整个页表就会超过3000万GB。这显然不科学啊！

因而，具有64位分页虚拟地址空间的系统需要一个不同的解决方案——**倒排分页（inverted page table）**。**在实际内存中每一个页框有一个表项，而不是每一个虚拟页面有一个表项**。例如，对于64位虚拟地址，4KB的页，1GB的RAM，一个倒排页表仅需要262144个页表项。**表项记录哪一个（进程，虚拟页面）对定位于该页框**。

虽然倒排页表节省了大量的空间，但也有严重的不足：**从虚拟地址到物理地址的转换会变得困难**。当进程n 访问虚拟页面p 时，硬件不再能通过把p 当做指向页表的一个索引来查找物理页框。取而代之的是，它必须搜索整个倒排页表来查找一个表项（n,p）。此外，该搜索必须对每一个内存访问操作都要执行一次，而不仅仅是在发生缺页中断时执行。这显然是不科学的！

还好我们之前学过缓存的思想和查找算法。顺序查找显然不科学，所以我们可以用散列表将虚拟地址散列，并结合TLB。问题得到解决！如下图所示：

![传统页表与倒排页表的对比](/image/REVERTED-TABLE)

## 总结

本文讨论了分页技术需要考虑的两个问题，加速分页和巨大虚拟地址空间管理的问题。加速分页利用缓存思想，使用硬件TLB来实现；而巨大虚拟空间地址利用了分级页表和倒排页表两种方式来解决。
