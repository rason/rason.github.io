TPS 问题排查经过

1. 首次压测 TPS 才 17，极其的低。

2. 发现是因为只有一个 kafka 消费者，于是将 spring.kafka.listener.concurrency 设置为 4 和 8 ，kafka partition 也对应设置 4 和 8 两种情况验证，TPS 达到了 40 多，还是太低。

3. 自己单独发一个请求，通过日志观察业务处理耗时才 50ms 左右，按这个耗时，1 个消费者线程同步处理极限 TPS 应该是 20，4个的极限应该是 80，当然因为 CPU 核心数限制以及时间片轮候不可能达到这个极限数。所以猜测难道这个 40 多的 TPS 真的是极限了？按照消费者同步处理完一个消息再处理下一个消息，好像极限就是这样了。

4. 于是将 kafka listener 接收到消息之后，丢给线程池来进行业务处理，这样就不用等待一条消息处理完再处理下一条了。改造之后继续压测，发现 TPS 还是 40 多，这就相当的奇怪了。

5. 猜测难道我们压测的速度不够快，一秒钟并没有那么多的消息发送到 kafka，不会是压测脚本有问题吧。于是修改脚本，观察发送速度，用两台机器同时压测，结果 TPS 还是 40 多。

6. 难道是 MQTT 转 kakfa 这里出现瓶颈了，因为我们脚本发送的是 MQTT 消息，会有 MQTT borker 到 kafka 这样的一个转换，所以又猜测是因为 MQTT broker 性能影响导致一秒钟没有那么多消息堆积到 kafka。

7. 后来想，为什么要一边堆积一边消费呢，直接把消费者停掉，先把消息堆积到 kafka 不就肯定有足够的消息堆积了吗？然后我们就先堆积，然后启动消费者，将 kafka 的 debug 日志打开了，观察到一次性取回了 500 条消息，结果 TPS 依然是 40 多。

8. 