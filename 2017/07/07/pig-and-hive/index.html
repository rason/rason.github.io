<!DOCTYPE html>

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=0">

  <meta name="description" content="Pig structure format and import to hive dw">


<link rel="alternate" href="/atom.xml" title="Rason&#39;s Blog" type="application/atom+xml">
<meta name="theme-color" content="#a1d0f6">
<title>使用Pig结构化日志然后导入到Hive数据仓库 - Rason&#39;s Blog</title>
<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
<link rel="shortcut icon" href="/favicon.png">
<link rel="stylesheet" href="/css/style.css">
<nav class="main-nav">
	
	    <a href="/">← Home</a>
	
	
	    <a href="/about/">About</a>
	
	    <a href="/archives/">Archives</a>
	
</nav>


<section id="wrapper">
    <article class="post">
    <header>
        
            <h1>使用Pig结构化日志然后导入到Hive数据仓库</h1>
        
        <h2 class="headline">Jul 07 2017
        
            
            <a href="/categories/BigData/#BigData">BigData</a>
        
        </h2>
    </header>
</article>
<section id="post-body"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>接着上篇文章，我们已经将日志通过Flume收集到了HDFS中，那么接下来就是使用Pig将日志内容结构化，然后保存到Hive数据仓库中。</p>
<h2 id="Pig安装"><a href="#Pig安装" class="headerlink" title="Pig安装"></a>Pig安装</h2><p>1.下载最近稳定版的Pig,<a href="http://hadoop.apache.org/pig/releases.html" target="_blank" rel="noopener">点这里</a>.</p>
<p>2.解压，修改<code>/etc/profile</code>文件配置环境变量<code>$ export PATH=/&lt;my-path-to-pig&gt;/pig-n.n.n/bin:$PATH</code></p>
<p>3.<code>$ source /etc/profile</code>使环境变量生效</p>
<p>4.测试安装是否成功<code>$ pig -help</code></p>
<h2 id="运行Pig"><a href="#运行Pig" class="headerlink" title="运行Pig"></a>运行Pig</h2><p>本例子接着之前的教程，前提需要已经部署好的Hadoop并且配置好其环境变量。</p>
<p>1.运行Pig</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pig</span><br></pre></td></tr></table></figure>
<p>2.进入HDFS文件系统根目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grunt&gt; cd hdfs://10.16.1.24/</span><br></pre></td></tr></table></figure>
<p>该目录是我前面教程中搭建的HDFS文件系统根目录。</p>
<p>3.查看根目录有哪些文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">grunt&gt; ls</span><br><span class="line">hdfs://10.16.1.24/flume	&lt;dir&gt;</span><br><span class="line">hdfs://10.16.1.24/output	&lt;dir&gt;</span><br><span class="line">hdfs://10.16.1.24/test	&lt;dir&gt;</span><br><span class="line">hdfs://10.16.1.24/tmp	&lt;dir&gt;</span><br><span class="line">hdfs://10.16.1.24/user	&lt;dir&gt;</span><br></pre></td></tr></table></figure>
<p>上篇文章中通过Flume收集的日志在<code>/flume</code>文件夹中。</p>
<p>4.结构化日志文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">grunt&gt; content = LOAD &apos;/flume/qhee/net/*&apos; USING PigStorage(&apos;\t&apos;) AS(domain:chararray,host:chararray,user:chararray,time:chararray,method:chararray,path:chararray,protocol:chararray,status:chararray,size:chararray,refer:chararray,agent:chararray,response_time:chararray,cookie:chararray,set_cookie:chararray,upstream_addr:chararray,upstream_cache_status:chararray,upstream_reponse_time:chararray);</span><br><span class="line"></span><br><span class="line">grunt&gt; DUMP content;</span><br><span class="line"></span><br><span class="line">grunt&gt; STORE content INTO &apos;output&apos; USING PigStorage (&apos;,&apos;);</span><br></pre></td></tr></table></figure>
<p>相关命令解析就不展开了，可以自行查看官方文档。</p>
<p>结构化之后的日志保存到了<code>output</code>目录中，所以上面的HDFS根目录中会有<code>output</code>这个文件夹，因为我之前已经执行过了。</p>
<p>可以将结构化的文件下载下来看看结果，发现其实就是将每个属性用逗号隔开了而已。做这项工作的主要目的就是为了方便导入到Hive仓库中，后面将会看到我们会以逗号为分隔符导入。</p>
<p>接下来该轮到Hive登场了。</p>
<a id="more"></a>
<h2 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h2><p>1.下载解压<a href="https://hive.apache.org/downloads.html" target="_blank" rel="noopener">Hive</a></p>
<p>2.类似Pig配置环境变量<code>$ export PATH=$HIVE_HOME/bin:$PATH</code></p>
<p>3.创建<code>$HIVE_HOME/conf/hive-site.xml</code>文件，内容如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;jdbc:mysql://10.16.2.28:3306/metastore?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;123456&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;datanucleus.fixedDatastore&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;datanucleus.autoCreateTables&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;True&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>此文件的作用是配置hive元数据保存的地方。</p>
<h2 id="运行Hive"><a href="#运行Hive" class="headerlink" title="运行Hive"></a>运行Hive</h2><p>1.运行Hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ $HIVE_HOME/bin/hive</span><br></pre></td></tr></table></figure>
<p>这个操作可能会遇到一下异常，可以通过<code>hive -hiveconf hive.root.logger=DEBUG,console</code>将日志输出到控制台方便查看。</p>
<p>我在启动过程中遇到了些小问题，是由于保存元数据的metastore数据库某些表创建失败导致，可以自己手动创建。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd $HIVE_HOME/scripts/metastore/upgrade/mysql/</span><br><span class="line"></span><br><span class="line">&lt; Login into MySQL &gt;</span><br><span class="line"></span><br><span class="line">mysql&gt; drop database IF EXISTS metastore;</span><br><span class="line">mysql&gt; create database metastore;</span><br><span class="line">mysql&gt; use metastore;</span><br><span class="line">mysql&gt; source hive-schema-2.1.0.mysql.sql;</span><br></pre></td></tr></table></figure>
<p>2.创建元数据数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create database qhee_net;</span><br><span class="line">hive&gt; use qhee_net;</span><br></pre></td></tr></table></figure>
<p>3.创建表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; Create table access_log</span><br><span class="line">    &gt; (</span><br><span class="line">    &gt;  host String,</span><br><span class="line">    &gt;  remote_addr String,</span><br><span class="line">    &gt;  remote_user String,</span><br><span class="line">    &gt;  time_local String,</span><br><span class="line">    &gt;  request_method String,</span><br><span class="line">    &gt;  request_uri String,</span><br><span class="line">    &gt;  server_protocol String,</span><br><span class="line">    &gt;  status String,</span><br><span class="line">    &gt;  body_bytes_sent String,</span><br><span class="line">    &gt;  http_referer String,</span><br><span class="line">    &gt;  http_user_agent String,</span><br><span class="line">    &gt;  request_time String,</span><br><span class="line">    &gt;  http_cookie String,</span><br><span class="line">    &gt;  sent_http_set_cookie String,</span><br><span class="line">    &gt;  upstream_addr String,</span><br><span class="line">    &gt;  upstream_cache_status String,</span><br><span class="line">    &gt;  upstream_response_time String                       </span><br><span class="line">    &gt; )</span><br><span class="line">    &gt; ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos;;</span><br></pre></td></tr></table></figure>
<p>重点是最后一行，指定了逗号分隔符（Pig结构化时所做的工作），这样就可以将数据对应导入。</p>
<p>4.加载数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA INPATH &apos;hdfs://10.16.1.24/output/part-m-00000&apos; OVERWRITE INTO TABLE access_log;</span><br><span class="line">Loading data to table qhee_net.access_log</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.251 seconds</span><br></pre></td></tr></table></figure>
<p>5.测试数据查询</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select remote_addr from access_log;</span><br><span class="line">OK</span><br><span class="line">10.8.30.19</span><br><span class="line">10.8.30.19</span><br><span class="line">10.8.30.19</span><br><span class="line">10.8.30.19</span><br><span class="line">10.8.30.19</span><br><span class="line">10.8.30.19</span><br><span class="line">10.8.30.19</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文简单地演示了使用Pig对数据进行结构化，然后导入到Hive数据仓库中，并没有深入更多的细节，仅起到领入门的作用。</p>
</section>
    
        
        <h2 class="footline">
            <a href="/tags/Pig/#Pig">Pig</a>
        </h2>
    

    <footer id="post-meta" class="clearfix">
        <a href="/about/">
        <img class="avatar" src="/images/avatar.png">
        <div>
            <span class="dark">Rason&#39;s Blog</span>
            <span></span>
        </div>
        </a>
        <section id="sharing">
            <a title="Share to Twitter" class="twitter" href="https://twitter.com/intent/tweet?text=http://ideajava.com/2017/07/07/pig-and-hive/ - 使用Pig结构化日志然后导入到Hive数据仓库 @"><span class="icon-twitter">tweet</span></a>
            <a title="Share to Facebook" class="facebook" href="#" onclick="
                window.open(
                  'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
                  'facebook-share-dialog',
                  'width=626,height=436');
                return false;"><span class="icon-facebook-sign">Share</span>
            </a>
        </section>
    </footer>


	<footer id="footer">
	<div id="social">
		<p class="small">©  rason| Powered by Hexo 
	
	<a href="http://www.beian.miit.gov.cn" target="_blank">粤ICP备17046371号-1</a></p>
	</div>
</footer>

</section>

	<script src="//cdnjs.loli.net/ajax/libs/instantclick/3.0.1/instantclick.min.js" data-no-instant=""></script>
	<script data-no-instant="">
		
		InstantClick.init('mousedown');
	</script>



