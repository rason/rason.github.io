<!DOCTYPE html>

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=0">

  <meta name="description" content="Hadoop Cluster Setup">


<link rel="alternate" href="/atom.xml" title="Rason&#39;s Blog" type="application/atom+xml">
<meta name="theme-color" content="#a1d0f6">
<title>Hadoop集群部署 - Rason&#39;s Blog</title>
<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
<link rel="shortcut icon" href="/favicon.png">
<link rel="stylesheet" href="/css/style.css">
<nav class="main-nav">
	
	    <a href="/">← Home</a>
	
	
	    <a href="/about/">About</a>
	
	    <a href="/archives/">Archives</a>
	
</nav>


<section id="wrapper">
    <article class="post">
    <header>
        
            <h1>Hadoop集群部署</h1>
        
        <h2 class="headline">Jul 03 2017
        
            
            <a href="/categories/BigData/#BigData">BigData</a>
        
        </h2>
    </header>
</article>
<section id="post-body"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一篇文章学习了Hadoop的单机部署和伪分布式部署，今天来学习一个集群式部署。本文不包含高级主题，比如安全和高可用。</p>
<p>通常，集群中的一个机器被指定为NameNode，另一台机器被指定为ResourceManager。 这些是Master。 其他服务（如Web App Proxy Server和MapReduce Job History server）通常在专用硬件或共享基础架构上运行，具体取决于负载。</p>
<p>集群中的其余机器充当DataNode和NodeManager。 这些是Slaves。</p>
<h2 id="机器分配"><a href="#机器分配" class="headerlink" title="机器分配"></a>机器分配</h2><p>为了简单起见，我用三台机器来演示集群部署。如下所示：</p>
<table>
<thead>
<tr>
<th>10.16.1.24</th>
<th>10.16.1.25</th>
<th>10.16.2.28</th>
</tr>
</thead>
<tbody>
<tr>
<td>主机名：QHEE-T-Crawler</td>
<td>主机名：QHEE-T-Crawler2</td>
<td>主机名：QHEE-T-CrawlerDB</td>
</tr>
<tr>
<td>NameNode</td>
<td>ResourceManager</td>
<td>SecondaryNameNode</td>
</tr>
<tr>
<td>DateNode</td>
<td>DateNode</td>
<td>DateNode</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>MRHistroyServer</td>
<td></td>
</tr>
</tbody>
</table>
<p>在配置文件 <code>/etc/hosts</code> 中添加主机名映射</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.16.1.24 QHEE-T-Crawler</span><br><span class="line">10.16.1.25 QHEE-T-Crawler2</span><br><span class="line">10.16.2.28 QHEE-T-CrawlerDB</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop集群配置"><a href="#Hadoop集群配置" class="headerlink" title="Hadoop集群配置"></a>Hadoop集群配置</h2><p>1.为了管理方便，将集群中的组件都安装配置在相同的目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@QHEE-T-Crawler /home/laixs/hadoop-2.8.0]#</span><br></pre></td></tr></table></figure>
<p>我使用的hadoop是2.8.0版本，都解压到<code>/home/laixs</code>目录中。</p>
<p>2.配置JDK。</p>
<p>修改<code>etc/hadoop/hadoop-env.shZ</code>， <code>etc/hadoop/mapred-env.sh</code> 和 <code>etc/hadoop/yarn-env.sh</code>三个配置文件指定JAVA_HOME</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=&quot;/usr/java/jdk1.8.0_131&quot;</span><br></pre></td></tr></table></figure>
<p>3.配置相关服务组件XML。</p>
<ul>
<li><code>etc/hadoop/core-site.xm</code>配置NameNode</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://10.16.1.24:8020&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/laixs/hadoop-2.8.0/data/tmp&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>etc/hadoop/slaves</code>文件配置DataNode</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.16.1.24 QHEE-T-Crawler</span><br><span class="line">10.16.1.25 QHEE-T-Crawler2</span><br><span class="line">10.16.2.28 QHEE-T-CrawlerDB</span><br></pre></td></tr></table></figure>
<ul>
<li><code>etc/hadoop/hdfs-site.xml</code>文件配置SecondaryNameNode</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;10.16.2.28:50090&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>etc/hadoop/yarn-site.xml</code>文件配置YARN</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;10.16.1.25&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;yarn.log.aggregation-enable&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;18000&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>具体每项配置解析可以看<a href="https://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml" target="_blank" rel="noopener">yarn-default.xml</a>。</p>
<ul>
<li><code>etc/hadoop/mapred-site.xml</code>文件配置MapReduce</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;10.16.1.24:10020&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">           &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;10.16.1.24:19888&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>先在一台机器上测试各个服务，没问题之后再将配置文件同步到其它节点。然后再测试其它节点启动有没有问题，启动任何服务如果有问题都应该根据日志报出的异常来进行解决。</p>
<p>以下是各项服务启动命令，按照文章开头的机器作用分配启动相关服务。</p>
<ul>
<li>启动namenode</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<ul>
<li>启动datanode</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
<ul>
<li>启动secondarynamenode</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/hadoop-daemon.sh start secondarynamenode</span><br></pre></td></tr></table></figure>
<ul>
<li>启动resourcemanager</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<ul>
<li>启动nodemanager</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure>
<ul>
<li>启动historyserver </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<ul>
<li>使用<code>jps</code>命令查看启动的进程：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@QHEE-T-Crawler /home/laixs/hadoop-2.8.0/etc/hadoop]# jps</span><br><span class="line">29077 NodeManager</span><br><span class="line">2566 Jps</span><br><span class="line">2551 NameNode</span><br><span class="line">31448 JobHistoryServer</span><br><span class="line">28443 DataNode</span><br></pre></td></tr></table></figure>
<ul>
<li>测试HDFS能否创建目录、上传文件、读取文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -mkdir /test</span><br><span class="line"></span><br><span class="line">$ bin/hdfs dfs -put /etc/hosts /test/</span><br><span class="line"></span><br><span class="line">$ bin/hdfs dfs -text /test/hosts</span><br></pre></td></tr></table></figure>
<h2 id="同步配置文件"><a href="#同步配置文件" class="headerlink" title="同步配置文件"></a>同步配置文件</h2><p>初步测试地一台机器没问题的话就可以把配置文件同步到另外两台机器，然后启动相关服务进行测试。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scp -r etc/ root@10.16.1.25:/home/laixs/hadoop-2.8.0/</span><br><span class="line">$ scp -r etc/ root@10.16.2.28:/home/laixs/hadoop-2.8.0/</span><br></pre></td></tr></table></figure>
<p>当所有节点的服务都启动起来之后，可以通过管理界面<code>http://10.16.1.24:50070</code>查看DataNode状态:</p>
<p><img src="/image/datanode.png" alt="DataNode"></p>
<h2 id="测试MapReduce"><a href="#测试MapReduce" class="headerlink" title="测试MapReduce"></a>测试MapReduce</h2><p>在NameNode节点上跑一个MapReduce作业，可以在<code>http://10.16.1.25:8088</code>查看进度：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /test/ /test/out</span><br></pre></td></tr></table></figure>
<p><img src="/image/yarn.png" alt="YARN"></p>
<p>作业执行完之后，可以通过<code>$ bin/hdfs dfs -cat /test/out/*</code>命令查看输出结果。</p>
<h2 id="可能存在的问题"><a href="#可能存在的问题" class="headerlink" title="可能存在的问题"></a>可能存在的问题</h2><p>在启动机器2的时候出现<code>java.net.UnknownHostException: QHEE-T-Crawler2: QHEE-T-Crawler2: Name or service not known</code>异常。</p>
<p>这是因为我一开始没有配置<code>/etc/hosts</code>文件，所有导致Host解析失败。</p>
<p>全文完。</p>
</section>
    
        
        <h2 class="footline">
            <a href="/tags/Hadoop/#Hadoop">Hadoop</a>
        </h2>
    

    <footer id="post-meta" class="clearfix">
        <a href="/about/">
        <img class="avatar" src="/images/avatar.png">
        <div>
            <span class="dark">Rason&#39;s Blog</span>
            <span></span>
        </div>
        </a>
        <section id="sharing">
            <a title="Share to Twitter" class="twitter" href="https://twitter.com/intent/tweet?text=http://ideajava.com/2017/07/03/hadoop-cluster-setup/ - Hadoop集群部署 @"><span class="icon-twitter">tweet</span></a>
            <a title="Share to Facebook" class="facebook" href="#" onclick="
                window.open(
                  'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
                  'facebook-share-dialog',
                  'width=626,height=436');
                return false;"><span class="icon-facebook-sign">Share</span>
            </a>
        </section>
    </footer>


	<footer id="footer">
	<div id="social">
		<p class="small">©  rason| Powered by Hexo 
	
	<a href="http://www.beian.miit.gov.cn" target="_blank">粤ICP备17046371号-1</a></p>
	</div>
</footer>

</section>

	<script src="//cdnjs.loli.net/ajax/libs/instantclick/3.0.1/instantclick.min.js" data-no-instant=""></script>
	<script data-no-instant="">
		
		InstantClick.init('mousedown');
	</script>



