<!DOCTYPE html>

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=0">

  <meta name="description" content="Flume HDFS">


<link rel="alternate" href="/atom.xml" title="Rason&#39;s Blog" type="application/atom+xml">
<meta name="theme-color" content="#a1d0f6">
<title>使用Flume将日志收集到HDFS - Rason&#39;s Blog</title>
<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
<link rel="shortcut icon" href="/favicon.png">
<link rel="stylesheet" href="/css/style.css">
<nav class="main-nav">
	
	    <a href="/">← Home</a>
	
	
	    <a href="/about/">About</a>
	
	    <a href="/archives/">Archives</a>
	
</nav>


<section id="wrapper">
    <article class="post">
    <header>
        
            <h1>使用Flume将日志收集到HDFS</h1>
        
        <h2 class="headline">Jul 06 2017
        
            
            <a href="/categories/BigData/#BigData">BigData</a>
        
        </h2>
    </header>
</article>
<section id="post-body"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本着从日志分析这个实际案例来学习Hadoop相关大数据技术，搜索了相关的日志分析方案，决定采用下图的方式：</p>
<p><img src="/image/Log-Analysis-in-Hadoop.jpg" alt="Hadoop log analysis"></p>
<p>那么第一步当然就是将日志收集到HDFS中，前面两篇博客已经简单地入门了Flume和Hadoop的部署，那么就在此基础上进行日志收集工作。</p>
<h2 id="Nginx-日志格式配置"><a href="#Nginx-日志格式配置" class="headerlink" title="Nginx 日志格式配置"></a>Nginx 日志格式配置</h2><p>本文以Nginx为例，采集其Access Log，因此为了后续工作的进行，先配置Nginx日志记录格式，如下所示：</p>
<p>定义格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">log_format  main  &apos;$host\t&apos;</span><br><span class="line">                      &apos;$remote_addr\t&apos;</span><br><span class="line">                      &apos;$remote_user\t&apos;</span><br><span class="line">                      &apos;$time_local\t&apos;</span><br><span class="line">                      &apos;$request_method\t&apos;</span><br><span class="line">                      &apos;$request_uri\t&apos;</span><br><span class="line">                      &apos;$server_protocol\t&apos;</span><br><span class="line">                      &apos;$status\t&apos;</span><br><span class="line">                      &apos;$body_bytes_sent\t&apos;</span><br><span class="line">                      &apos;$http_referer\t&apos;</span><br><span class="line">                      &apos;$http_user_agent\t&apos;</span><br><span class="line">                      &apos;$request_time\t&apos;</span><br><span class="line">                      &apos;$http_cookie\t&apos;</span><br><span class="line">                      &apos;$sent_http_set_cookie\t&apos;</span><br><span class="line">                      &apos;$upstream_addr\t&apos;</span><br><span class="line">                      &apos;$upstream_cache_status\t&apos;</span><br><span class="line">                      &apos;$upstream_response_time&apos;;</span><br></pre></td></tr></table></figure>
<p>使用格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">access_log  logs/xxx.access.log main;</span><br></pre></td></tr></table></figure>
<h2 id="Flume配置"><a href="#Flume配置" class="headerlink" title="Flume配置"></a>Flume配置</h2><p>在Nginx机器上部署Flume，修改Flume按照目录下的<code>conf/example.conf</code>文件如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1 </span><br><span class="line">a1.sinks = k1 </span><br><span class="line">a1.channels = c1</span><br><span class="line">         </span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /usr/local/nginx/logs/www.qhee.net.access.log</span><br><span class="line"></span><br><span class="line"># Describe the sink </span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://10.16.1.24:8020/flume/qhee/net</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory </span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line">    </span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p>数据源使用<code>exec</code>类型来获取最新的访问日志，然后将其保存到HDFS中,保存路径是上篇文章中部署的HDFS。然后启动Flume:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup bin/flume-ng agent --conf conf --conf-file conf/example.conf --name a1 &amp;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="启动Flume可能存在的问题"><a href="#启动Flume可能存在的问题" class="headerlink" title="启动Flume可能存在的问题"></a>启动Flume可能存在的问题</h2><p><strong>1.</strong> hadoop 依赖问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Failed to start agent because dependencies were not found in classpath. Error follows.</span><br><span class="line">java.lang.NoClassDefFoundError: org/apache/hadoop/io/SequenceFile$CompressionType</span><br></pre></td></tr></table></figure>
<p>解决办法：将<code>/hadoop/share/hadoop/common/*.jar</code> 和<code>/hadoop/share/hadoop/common/lib/*.jar</code> 拷贝到flume安装目录的lib下。</p>
<p><strong>2.</strong> hdfs 依赖问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.io.IOException: No FileSystem for scheme: hdfs</span><br></pre></td></tr></table></figure>
<p>解决办法：将<code>/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-x.x.x.jar</code> 拷贝到flume的安装目录的lib下。</p>
<p><strong>3.</strong> 没有权限写 hdfs</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.security.AccessControlException: Permission denied: user=xxx, access=WRITE,</span><br></pre></td></tr></table></figure>
<p>解决办法：使用管理账户开启hdfs写权限或者配置conf/hdfs-site.xml关闭权限控制</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h2 id="查看HDFS收集结果"><a href="#查看HDFS收集结果" class="headerlink" title="查看HDFS收集结果"></a>查看HDFS收集结果</h2><p>启动Flume如果没有问题，那么在Hadoop的控制台页面应该能看到收集的日志，如下图所示：</p>
<p><img src="/image/flume-log.png" alt="Collected Log"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文比较简单，都是一些配置工作，先配置Nginx的日志记录格式，然后配置Flume将日志收集到HDFS中。接下来将会继续学习使用Pig将日志结构化，然后将其存储到Hive数据仓库中。</p>
</section>
    
        
        <h2 class="footline">
            <a href="/tags/Flume/#Flume">Flume</a>
        </h2>
    

    <footer id="post-meta" class="clearfix">
        <a href="/about/">
        <img class="avatar" src="/images/avatar.png">
        <div>
            <span class="dark">Rason&#39;s Blog</span>
            <span></span>
        </div>
        </a>
        <section id="sharing">
            <a title="Share to Twitter" class="twitter" href="https://twitter.com/intent/tweet?text=http://ideajava.com/2017/07/06/flume-log-collect/ - 使用Flume将日志收集到HDFS @"><span class="icon-twitter">tweet</span></a>
            <a title="Share to Facebook" class="facebook" href="#" onclick="
                window.open(
                  'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
                  'facebook-share-dialog',
                  'width=626,height=436');
                return false;"><span class="icon-facebook-sign">Share</span>
            </a>
        </section>
    </footer>


	<footer id="footer">
	<div id="social">
		<p class="small">©  rason| Powered by Hexo 
	
	<a href="http://www.beian.miit.gov.cn" target="_blank">粤ICP备17046371号-1</a></p>
	</div>
</footer>

</section>

	<script src="//cdnjs.loli.net/ajax/libs/instantclick/3.0.1/instantclick.min.js" data-no-instant=""></script>
	<script data-no-instant="">
		
		InstantClick.init('mousedown');
	</script>



