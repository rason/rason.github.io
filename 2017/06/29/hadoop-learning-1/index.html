<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword" content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Hadoop初体验
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i>  </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/spring.png">
        </div>
        <div class="name">
            <i>rason</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li>
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>HOME</span>
                </a>
            </li>
<!--            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>TAGS</span>
                </a>
            </li>
    -->        <li>
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>ARCHIVES</span>
                </a>
            </li>
            <li>
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>ABOUT</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#背景"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#准备工作"><span class="toc-text">准备工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运行Hadoop"><span class="toc-text">运行Hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运行模式"><span class="toc-text">运行模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#单机模式"><span class="toc-text">单机模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#伪分布式"><span class="toc-text">伪分布式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#配置"><span class="toc-text">配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ssh免密配置"><span class="toc-text">ssh免密配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#执行"><span class="toc-text">执行</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#在单节点上运行YARN框架"><span class="toc-text">在单节点上运行YARN框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#可能出现的问题"><span class="toc-text">可能出现的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input">
            <span id="begin-search">search</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i>  </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Hadoop初体验
    </div>

    <div class="post-meta">
        <span class="attr">Post：<span>2017-06-29 14:01:48</span></span>
        
        <span class="attr">Tags：/
        
        <a class="tag" href="/tags/#Hadoop" title="Hadoop">Hadoop</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">Visit：<span id="busuanzi_value_page_pv"></span>
</span>

    </div>
    <div class="post-content ">
        <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>上篇文章学习了Flume框架，可以用于日志的收集，收集之后的日志需要有一个地方来存储。HDFS就是其中的一种方式，所以，顺着路线我需要学习一下HDFS。</p>
<p>HDFS只是Hadoop的一部分，解决分布式文件存储问题；另外重要的一部分就是MapReduce，解决分布式计算的问题。</p>
<p>今天这篇文章介绍如何设置和配置单节点Hadoop安装，以便你可以使用Hadoop MapReduce和Hadoop分布式文件系统（HDFS）快速执行简单的操作。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul>
<li>系统：windows或者linux都可以，我的机器是linux</li>
<li>JDK7以上</li>
<li>ssh </li>
<li>rsync</li>
<li><a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/" target="_blank" rel="noopener">hadoop</a></li>
</ul>
<h2 id="运行Hadoop"><a href="#运行Hadoop" class="headerlink" title="运行Hadoop"></a>运行Hadoop</h2><p>解压下载的Hadoop发行版。修改<code>etc/hadoop/hadoop-env.sh</code>文件，添加JAVA_HOME路径：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># set to the root of your Java installation</span><br><span class="line">export JAVA_HOME=/usr/java/latest</span><br></pre></td></tr></table></figure>
<p>然后运行一下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop</span><br></pre></td></tr></table></figure>
<p>会展示hadoop脚本的使用文档。</p>
<h2 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h2><p>现在，你可以使用三种支持的模式之一启动Hadoop集群：</p>
<ul>
<li>单机模式</li>
<li>伪分布式</li>
<li>完全分布式</li>
</ul>
<p>今天我们先学习前两种，后一种将在以后学习。</p>
<h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p>默认情况下，Hadoop作为单一的Java进程以非分布式的模式运行。在Debug的时候很有用。</p>
<p>下面的例子将复制配置文件目录的内容作为输入，查找并显示匹配给定正则表达式的条目。输出写入到指定的 output 目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir input</span><br><span class="line">$ cp etc/hadoop/*.xml input</span><br><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar grep input output &apos;dfs[a-z.]+&apos;</span><br><span class="line">$ cat output/*</span><br></pre></td></tr></table></figure>
<p>第三行命令是一个MapReduce 作业，查找匹配的内容输出。</p>
<a id="more"></a>
<h2 id="伪分布式"><a href="#伪分布式" class="headerlink" title="伪分布式"></a>伪分布式</h2><p>Hadoop也可以以伪分布式模式运行在单节点上，其中每个Hadoop守护程序在单独的Java进程中运行。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p><em>etc/hadoop/core-site.xml:</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p><em>etc/hadoop/hdfs-site.xml:</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h3 id="ssh免密配置"><a href="#ssh免密配置" class="headerlink" title="ssh免密配置"></a>ssh免密配置</h3><p>先检查一下ssh能否免密连接到localhost:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh localhost</span><br></pre></td></tr></table></figure>
<p>如果不行，执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -P &apos;&apos; -f ~/.ssh/id_rsa</span><br><span class="line">$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">$ chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>
<h3 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h3><p>下面的指令将在本地运行一个MapReduce作业。</p>
<p>1.格式化文件系统：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>2.启动NameNode和DataNode守护进程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>Hadoop守护进程日志输入到<code>$HADOOP_LOG_DIR</code>目录（默认是 <code>$HADOOP_HOME/logs</code>）。</p>
<p>3.浏览NameNode的web界面，默认地址是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:50070/</span><br></pre></td></tr></table></figure>
<p>4.创建运行MapReduce 作业所需要的HDFS目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -mkdir /user</span><br><span class="line">$ bin/hdfs dfs -mkdir /user/&lt;username&gt;</span><br></pre></td></tr></table></figure>
<p>注意用户名不要搞错。</p>
<p>5.复制输入文件到分布式文件系统中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -put etc/hadoop input</span><br></pre></td></tr></table></figure>
<p>6.运行Hadoop发行版提供的一些MapReduce 例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure>
<p>7.检验一下输出结果：将分布式文件系统中的output文件夹拷贝到本地进行检验：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -get output output</span><br><span class="line">$ cat output/*</span><br></pre></td></tr></table></figure>
<p>或者，你也可以直接在分布式文件系统中查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p>8.作业完成之后，停止守护进程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>
<h2 id="在单节点上运行YARN框架"><a href="#在单节点上运行YARN框架" class="headerlink" title="在单节点上运行YARN框架"></a>在单节点上运行YARN框架</h2><p>你也可以通过设置几个参数并运行ResourceManager守护程序和NodeManager守护程序，在伪分布式模式下运行YARN上的MapReduce作业。</p>
<p>需要先执行上面的前四个步骤，然后执行下面指令：</p>
<p>1.配置参数</p>
<p><em>etc/hadoop/mapred-site.xml</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p><em>etc/hadoop/yarn-site.xml</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>2.启动ResourceManager和NodeManager守护进程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>3.浏览ResourceManager的web界面，默认地址是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8088/</span><br></pre></td></tr></table></figure>
<p>4.运行一个MapReduce作业</p>
<p>你可以选择再次执行上面例子的作业。</p>
<p>5.完成之后，停止守护进行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>
<h2 id="可能出现的问题"><a href="#可能出现的问题" class="headerlink" title="可能出现的问题"></a>可能出现的问题</h2><p>按照教程跑第二第三个例子，如果多次执行了<code>$ bin/hdfs namenode -format</code>命令对namenode进行格式化，可能会导致datanode的clusterID跟namenode的clusterID不对应，然后datanode启动失败。</p>
<p>在启动日志中可以看到<code>java.io.IOException: Incompatible clusterIDs</code>的异常信息，解决方法很简单，只要让datanode的clusterID跟namenode的clusterID对应起来就行了。可以选择大家同时格式化掉从新来，也可以选择修改datanode的clusterID跟namenode的一致就行了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>初次接触Hadoop，对HDFS和MapReduce有了基础的了解，并能够在本机上运行简单的MapReduce作业。</p>

        
        <br>
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
<!--        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
    Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p> -->
</p></footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = ""
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
